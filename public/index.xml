<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amazon SageMaker Workshop</title>
    <link>https://sagemaker-workshop.com/</link>
    <description>Recent content on Amazon SageMaker Workshop</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://sagemaker-workshop.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SageMaker Resources</title>
      <link>https://sagemaker-workshop.com/cleanup/sagemaker.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/cleanup/sagemaker.html</guid>
      <description>To avoid charges for resources you no longer need when you&amp;rsquo;re done with this workshop, you can delete them or, in the case of your notebook instance, stop them. Here are the resources you should consider:
Endpoints: these are the clusters of one or more instances serving inferences from your models. If you did not delete them from within a notebook, you can delete them via the SageMaker console. To do so:</description>
    </item>
    
    <item>
      <title>Scenario</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/scenario.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/scenario.html</guid>
      <description>You are a member of a Cloud Platform Engineering team that has been tasked with enabling your business&amp;rsquo;s data scientists to deliver machine learning-based projects that are trained on highly sensitive company and customer data. The project teams are constrained by shared on-premise resources so you have been tasked with determining how the business can leverage the cloud to provision environments for the data science teams. The environment must be secure, protecting the sensitive data, while also enabling the data science teams to self-service.</description>
    </item>
    
    <item>
      <title>Scenario</title>
      <link>https://sagemaker-workshop.com/security_for_users/scenario.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/scenario.html</guid>
      <description>You are a data scientist or ML engineer who works at a company that wishes to enable their data scientists to deliver machine learning-based projects that are trained on highly sensitive company data. The project teams are constrained by shared on-premise resources so your sysops admins have created all the infrastructure-as-code templates needed to provision a secure environment, which protects the sensitive data while also enabling the data science teams to self-service.</description>
    </item>
    
    <item>
      <title>Submit custom code</title>
      <link>https://sagemaker-workshop.com/custom/code.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/custom/code.html</guid>
      <description>In this section, you will train a neural network locally on the location from where this notebook is run (typically the SageMaker Notebook instance) using MXNet. You will then see how to create an endpoint from the trained MXNet model and deploy it on SageMaker. You will then inference from the newly created SageMaker endpoint. For this section, you&amp;rsquo;ll be using the MNIST dataset.
Running the notebook Download the mxnet_mnist_byom.zip file.</description>
    </item>
    
    <item>
      <title>Video Game Sales Prediction with XGBoost</title>
      <link>https://sagemaker-workshop.com/builtin/xgboost.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/builtin/xgboost.html</guid>
      <description>In this section, you&amp;rsquo;ll work your way through a Jupyter notebook that demonstrates how to use a built-in algorithm in SageMaker. More specifically, we&amp;rsquo;ll use SageMaker&amp;rsquo;s version of XGBoost, a popular and efficient open-source implementation of the gradient boosted trees algorithm.
Gradient boosting is a supervised learning algorithm that attempts to predict a target variable by combining the estimates of a set of simpler, weaker models. XGBoost has done remarkably well in machine learning competitions because it robustly handles a wide variety of data types, relationships, and distributions.</description>
    </item>
    
    <item>
      <title>What Have We Accomplished</title>
      <link>https://sagemaker-workshop.com/conclusion/conclusion.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/conclusion/conclusion.html</guid>
      <description>We have:
Created a SageMaker Notebook instance Explored different built-in algorithms Analyzed strategies to distribute data for parallel training Trained a model using a custom script Built and deployed a custom model </description>
    </item>
    
    <item>
      <title>Image Classification with ResNet</title>
      <link>https://sagemaker-workshop.com/builtin/resnet.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/builtin/resnet.html</guid>
      <description>In this section, you&amp;rsquo;ll work your way through a Jupyter notebook that demonstrates how to use a built-in algorithm in SageMaker. More specifically, you&amp;rsquo;ll use SageMaker&amp;rsquo;s image classification algorithm, a supervised learning algorithm that takes an image as input and classifies it into one of multiple output categories. It uses a convolutional neural network (ResNet) that can be trained from scratch, or trained using transfer learning when a large number of training images are not available.</description>
    </item>
    
    <item>
      <title>Tools</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/tools.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/tools.html</guid>
      <description>To work through these labs you will need:
An AWS account
With privileges to create IAM roles, attach IAM policies, create AWS VPCs, configure Service Catalog, create Amazon S3 buckets, and work with Amazon SageMaker.
Access to the AWS web console
Many of the instructions will guide you through working with the various service consoles.
Jupyter cheat sheet
If you are unfamiliar with the Jupyter notebook interface or its keybindings a cheat sheet may help you navigate.</description>
    </item>
    
    <item>
      <title>Tools &amp; Knowledge Check</title>
      <link>https://sagemaker-workshop.com/security_for_users/tools.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/tools.html</guid>
      <description>To work through these labs you will need:
An AWS account
With privileges to create IAM roles, attach IAM policies, create AWS VPCs, configure Service Catalog, create Amazon S3 buckets, and work with Amazon SageMaker.
Access to the AWS web console
Many of the instructions will guide you through working with the various service consoles.
To get the most of these labs it will be beneficial if you have prior experience working with the following technologies:</description>
    </item>
    
    <item>
      <title>Anomaly Detection with Random Cut Forest</title>
      <link>https://sagemaker-workshop.com/builtin/rcf.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/builtin/rcf.html</guid>
      <description>In this section, you&amp;rsquo;ll work your way through a Jupyter notebook that demonstrates how to use a built-in algorithm in SageMaker. More specifically, you&amp;rsquo;ll use SageMaker&amp;rsquo;s Random Cut Forest (RCF) algorithm, an algorithm designed to detect anomalous data points within a dataset. Examples of when anomalies are important to detect include when website activity uncharacteristically spikes, when temperature data diverges from a periodic behaviour, or when changes to public transit ridership reflect the occurrence of a special event.</description>
    </item>
    
    <item>
      <title>Use your own custom algorithms</title>
      <link>https://sagemaker-workshop.com/custom/algo.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/custom/algo.html</guid>
      <description>In this section, you&amp;rsquo;ll create your own training script using TensorFlow and the building blocks provided in tf.layers, which will predict the ages of abalones based on their physical measurements. It&amp;rsquo;s possible to estimate the age of an abalone (sea snail) by the number of rings on its shell. In this section, you&amp;rsquo;ll be using the UCI Abalone dataset.
Writing Custom TensorFlow Model Training and Inference Code To train a model on Amazon SageMaker using custom TensorFlow code and deploy it on Amazon SageMaker, you need to implement training and inference code interfaces in your code.</description>
    </item>
    
    <item>
      <title>Parallelized Data Distribution</title>
      <link>https://sagemaker-workshop.com/builtin/parallelized.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/builtin/parallelized.html</guid>
      <description>SageMaker makes it easy to train machine learning models across a cluster containing a large number of machines. This a non-trivial process, but SageMaker&amp;rsquo;s built-in algorithms and pre-built MXNet and TensorFlow containers hide most of the complexity from you. Nevertheless, there are decisions about how to structure data that will have implications regarding how the distributed training is carried out.
In this section, you will learn about how to take full advantage of distributed training clusters when using one of SageMaker&amp;rsquo;s built-in algorithms.</description>
    </item>
    
    <item>
      <title>CloudFormation Stacks</title>
      <link>https://sagemaker-workshop.com/cleanup/workspace.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/cleanup/workspace.html</guid>
      <description>To delete all the underlying resources, assume the Account Admin Role and navigate to CloudFormation.
If the &amp;ldquo;view nested&amp;rdquo; button is checked, click on it, so you only see the root stacks. You should see a root stack associated with the Notebook, one associated with the DS Environment and a secure-ds-core stack which builds the core environment with the Shared Services VPC. Delete this one last.
Step by Step Instructions</description>
    </item>
    
    <item>
      <title>Overview of containers for Amazon SageMaker</title>
      <link>https://sagemaker-workshop.com/custom/containers.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/custom/containers.html</guid>
      <description>SageMaker makes extensive use of Docker containers to allow users to train and deploy algorithms. Containers allow developers and data scientists to package software into standardized units that run consistently on any platform that supports Docker. Containerization packages code, runtime, system tools, system libraries and settings all in the same place, isolating it from its surroundings, and insuring a consistent runtime regardless of where it is being run.
When you develop a model in Amazon SageMaker, you can provide separate Docker images for the training code and the inference code, or you can combine them into a single Docker image.</description>
    </item>
    
    <item>
      <title>Security Overview</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/security_overview.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/security_overview.html</guid>
      <description>Amazon SageMaker is a powerful enabler and a key component of a data science environment, but it&amp;rsquo;s only part of what is required to build a complete secure data science environment. For more robust security you will need other AWS services such as Amazon CloudWatch, Amazon S3, and AWS VPC. To begin, let&amp;rsquo;s talk about some of the key things you will want in place, working in concert, with Amazon SageMaker.</description>
    </item>
    
    <item>
      <title>Security Overview</title>
      <link>https://sagemaker-workshop.com/security_for_users/security_overview.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/security_overview.html</guid>
      <description>Amazon SageMaker is a powerful enabler and a key component of a data science environment, but it&amp;rsquo;s only part of what is required to build a complete secure data science environment. For more robust security you will need other AWS services such as Amazon CloudWatch, Amazon S3, and AWS VPC. To begin, let&amp;rsquo;s talk about some of the key things you will want in place, working in concert, with Amazon SageMaker.</description>
    </item>
    
    <item>
      <title>Environment</title>
      <link>https://sagemaker-workshop.com/prerequisites/prerequisites.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/prerequisites/prerequisites.html</guid>
      <description>AWS Account In order to complete this workshop you&amp;rsquo;ll need an AWS Account, and an AWS IAM user in that account with at least full permissions to the following AWS services:
AWS IAM Amazon S3 Amazon SageMaker AWS Cloud9 Use Your Own Account: The code and instructions in this workshop assume only one student is using a given AWS account at a time. If you try sharing an account with another student, you&amp;rsquo;ll run into naming conflicts for certain resources.</description>
    </item>
    
    <item>
      <title>Machine Learning with Amazon SageMaker</title>
      <link>https://sagemaker-workshop.com/introduction/concepts.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/introduction/concepts.html</guid>
      <description>This section describes a typical machine learning workflow and summarizes how you accomplish those tasks with Amazon SageMaker.
In machine learning, you &amp;ldquo;teach&amp;rdquo; a computer to make predictions, or inferences. First, you use an algorithm and example data to train a model. Then you integrate your model into your application to generate inferences in real time and at scale. In a production environment, a model typically learns from millions of example data items and produces inferences in hundreds to less than 20 milliseconds.</description>
    </item>
    
    <item>
      <title>Secure Networking</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/team_resources/secure_networking.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/team_resources/secure_networking.html</guid>
      <description>Amazon SageMaker allows you to create resources attached to your AWS Virtual Private Cloud (VPC). This allows you to govern access to SageMaker resources and your data sets using familiar tools such as security groups, routing tables, and VPC endpoints. Using these network-layer tools you can create a secure network environment that allows you to explicitly control the data ingress and egress of your data science environment. Please take a few moments and read about these tools in more detail.</description>
    </item>
    
    <item>
      <title>Secure Notebooks</title>
      <link>https://sagemaker-workshop.com/security_for_users/environment/secure_notebook.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/environment/secure_notebook.html</guid>
      <description>Amazon SageMaker is designed to empower data scientists and developers, enabling them to build more quickly and remain focused on their machine learning project. One of the ways that SageMaker does this is by providing hosted Jupyter Notebook servers. With a single API call users can create a Jupyter Notebook server with the latest patches and kernels available. No need to install software, patch or maintain systems - it is all done for you.</description>
    </item>
    
    <item>
      <title>Security Objectives</title>
      <link>https://sagemaker-workshop.com/security_for_users/notebook/ml_lifecycle.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/notebook/ml_lifecycle.html</guid>
      <description>A secure environment is an enabler for teams, allowing them to focus on their project and the business challenge it is trying to solve. From the perspective of a project team the environment is intended to support the team in achieving the following objectives:
Compute and Network Isolation
In working with the Amazon SageMaker service you will need to configure training jobs and similar resources using practices inline with security policy.</description>
    </item>
    
    <item>
      <title>Lab 2: Secure Environment</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/team_resources/secure_environment_lab.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/team_resources/secure_environment_lab.html</guid>
      <description>A data science project team have requested a cloud environment to begin their project. As a project administrator you will use the Service Catalog portfolio, managed by the Cloud Platform Engineering team, to provision a secure VPC and related resources for the data science team. In this lab, you will use AWS Service Catalog to provision this data science environment. By following the steps below you will create an environment which contains:</description>
    </item>
    
    <item>
      <title>Jupyter Notebooks</title>
      <link>https://sagemaker-workshop.com/prerequisites/jupyter.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/prerequisites/jupyter.html</guid>
      <description>Jupyter is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modelling, data visualization, machine learning, and much more. With respect to code, it can be thought of as a web-based IDE that executes code on the server it is running on instead of locally.
There are two main types of &amp;ldquo;cells&amp;rdquo; in a notebook: code cells, and &amp;ldquo;markdown&amp;rdquo; cells with explanatory text.</description>
    </item>
    
    <item>
      <title>Lab 01: Deploy the environment</title>
      <link>https://sagemaker-workshop.com/security_for_users/environment/env_deploy_lab.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/environment/env_deploy_lab.html</guid>
      <description>In the following steps you will use AWS CloudFormation and AWS Service Catalog to create a self-service mechanism to create secure data science environments. You will first deploy a CloudFormation template which provisions a shared service environment which hosts a PyPI mirror along with a detective control to enforce Amazon SageMaker resources being attached to a VPC. The template will also create a product portfolio in AWS Service Catalog which enables users with appropriate permissions to create a data science environment dedicated to a single project.</description>
    </item>
    
    <item>
      <title>Lab 03: Data Science Workflow</title>
      <link>https://sagemaker-workshop.com/security_for_users/notebook/notebook_lab_01.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/notebook/notebook_lab_01.html</guid>
      <description>The ML lifecylce has many stages and steps, and often requires revisiting previous steps as you tune your model. This lab is intended to highlight how your project team can work through the ML lifecycle and achive the objectives outlined earlier through supporting services such as experiment tracking.
The notebook explained 01_SageMaker-DataScientist-Workflow.ipynb will cover a typical Data Scientist workflow of data exploration, model training, extracting model feature importances and committing your code to Git.</description>
    </item>
    
    <item>
      <title>Self-Service with Guard Rails</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/best_practice/service_catalog.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/best_practice/service_catalog.html</guid>
      <description>Allowing users in the cloud to self-service and provision cloud resources on-demand is a powerful enabler for project teams but can be a concern from an operational risk perspective. However, if you can empower your developers to self-service, while enforcing guard rails and best practice, then the operational and security teams will also benefit. With enforced guard rails and best practice you can be confident that, while developers are creating resources they need, they are doing so in a manner that is inline with your policies and requirements.</description>
    </item>
    
    <item>
      <title>Lab 1: Best Practice as Code</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/best_practice/best_practice_lab.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/best_practice/best_practice_lab.html</guid>
      <description>Before you can begin creating templates for deployment by the Project Administration team you will need a shared services VPC to host a Python package mirror (PyPI) for use by data science teams. The mirror will host a collection of approved Python packages. The concept of a shared services VPC or PyPI mirror is not something that is detailed in this workshop, and is partially assumed as common practice among many AWS customers.</description>
    </item>
    
    <item>
      <title>Cloud9 Setup</title>
      <link>https://sagemaker-workshop.com/prerequisites/cloud9.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/prerequisites/cloud9.html</guid>
      <description>AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes pre-packaged with essential tools for popular programming languages and the AWS Command Line Interface (CLI) pre-installed so you don’t need to install files or configure your laptop for this workshop. Your Cloud9 environment will have access to the same AWS resources as the user with which you logged into the AWS Management Console.</description>
    </item>
    
    <item>
      <title>Lab 04: DevOps Workflow</title>
      <link>https://sagemaker-workshop.com/security_for_users/notebook/notebook_lab_02.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/notebook/notebook_lab_02.html</guid>
      <description>In notebook 02_SageMaker-DevOps-Workflow.ipynb, you will complete the machine learning lifecycle and deliver a model into production. As a DevOps Engineer you will pick up the model trained by the data scientists and deploy it as an endpoint. You will also set up model monitoring on the endpoint for detecting data drift. This notebook is primarily focused on two aspects of running machine learning models in production, monitoring the model&amp;rsquo;s performance and being able to demonstrate the model&amp;rsquo;s lineage.</description>
    </item>
    
    <item>
      <title>Secure Notebooks</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/secure_notebook/secure_notebook.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/secure_notebook/secure_notebook.html</guid>
      <description>Amazon SageMaker is designed to empower data scientists and developers, enabling them to build more quickly and remain focused on their machine learning project. One of the ways that SageMaker does this is by providing hosted Jupyter Notebook servers. With a single API call users can create a Jupyter Notebook server with the latest patches and kernels available. No need to install software, patch or maintain systems - it is all done for you.</description>
    </item>
    
    <item>
      <title>Lab 02: Deploy a Notebook</title>
      <link>https://sagemaker-workshop.com/security_for_users/environment/secure_notebook_lab.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/environment/secure_notebook_lab.html</guid>
      <description>Your project team has been presented with IAM roles and a Service Catalog Portfolio to allow your team to self service and obtain resources to support your efforts. Following the steps below use this portfolio to create a Jupyter notebook instance for yourself.
Launch the notebook product Click into the details for the data science environment product you provisioned in the last step and find the link to assume the role of a data science user.</description>
    </item>
    
    <item>
      <title>Lab 3: Deploy a Jupyter Notebook</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/secure_notebook/secure_notebook_lab.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/secure_notebook/secure_notebook_lab.html</guid>
      <description>At this point, the cloud platform engineering team has built a self-service mechanism to provision secure environments to host data science projects. The project administrators have provisioned resources using the self-service mechanism for your team to work, and they have provided you with a self-service mechanism to enable you to provision SageMaker notebooks. Now, use these resources to provision a Jupyter notebook and start developing your ML solution.
Launch the notebook product Navigate to the AWS Service Catalog console and on go to the detail page for the recently provisioned data science environment.</description>
    </item>
    
    <item>
      <title>Creating a Notebook Instance</title>
      <link>https://sagemaker-workshop.com/introduction/notebook.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/introduction/notebook.html</guid>
      <description>SageMaker provides hosted Jupyter notebooks that require no setup, so you can begin processing your training data sets immediately. With a few clicks in the SageMaker console, you can create a fully managed notebook instance, pre-loaded with useful libraries for machine learning. You need only add your data.
You&amp;rsquo;ll start by creating an Amazon S3 bucket that will be used throughout the workshop. You&amp;rsquo;ll then create a SageMaker notebook instance, which you will use for the other workshop modules.</description>
    </item>
    
    <item>
      <title>Detective Controls</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/detective/detective_controls.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/detective/detective_controls.html</guid>
      <description>AWS recommends a defense-in-depth approach to security, applying security at every level of your application and environment. In this section we will focus on the concept of detective controls and incident response in the form of a corrective control. A detective control is responsible for identifying potential security threats or incidents while a corrective control is responsible for limiting the potential damage of the threat or incident after detection.
One example of a form of detective control is the use of internal auditing to ensure that an environment and user practice is inline with your policies and requirements.</description>
    </item>
    
    <item>
      <title>Lab 4: Detective and Corrective Controls</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/detective/detective_lab.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/detective/detective_lab.html</guid>
      <description>In this lab you will test a remediating detective control that was deployed by the cloud platform engineering team in Lab 1. The control is designed to detect the creation of Amazon SageMaker training jobs outside of the secure data science VPC and terminate them. To do this, you will go through the Jupyter notebook kernel 00_SageMaker-SysOps-Workflow and execute the cells up to and including the creation of a training job.</description>
    </item>
    
    <item>
      <title>Preventive Controls</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/preventive/preventive_controls.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/preventive/preventive_controls.html</guid>
      <description>Amazon SageMaker, like other services, is goverened by Identity and Access Management (IAM). You configure IAM using policy documents which explicitly grant permissions to your environment.
AWS IAM is based upon the concepts of Principals, Actions, Resources, and Conditions (PARC). This allows you to specify, using IAM policies who (principals) can do what (actions) to which resources and under what circumstances (conditions). Conditions are a powerful part of IAM policies and gives you the ability to control aspects of the actions being taken by principals in your environment.</description>
    </item>
    
    <item>
      <title>Lab 5: Preventive Controls</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/preventive/preventive_lab.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/preventive/preventive_lab.html</guid>
      <description>In this lab, you will implement a preventive control that will stop a training job from starting if it&amp;rsquo;s not launched within a VPC. In the interest of defence in depth you will implement the preventive control to complement the detective control exercised in the previous lab.
The preventive control you will deploy here is a modification to the IAM policy which grants a user&amp;rsquo;s notebook the permission to launch a training job.</description>
    </item>
    
    <item>
      <title>Summary</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/summary.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/summary.html</guid>
      <description>Let&amp;rsquo;s look back on what you&amp;rsquo;ve accomplished during the labs in this section.
In this series of labs you used many AWS services to support your machine learning process. As the Cloud Platform Engineering team you created a secure network environment with corrective controls for the data science administration team. You also created a self-service product that codified best practices and allowed the Data Science Administration team to support the data science project teams without needing expansive permissions in AWS.</description>
    </item>
    
    <item>
      <title>Summary</title>
      <link>https://sagemaker-workshop.com/security_for_users/summary.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/summary.html</guid>
      <description>Let&amp;rsquo;s look back on what you&amp;rsquo;ve accomplished during the labs in this section.
In this series of labs you used many AWS services to support your machine learning process. As the Cloud Platform Engineering team you created a secure network environment with corrective controls for the data science administration team. You also created a self-service product that codified best practices and allowed the Data Science Administration team to support the data science project teams without needing expansive permissions in AWS.</description>
    </item>
    
    <item>
      <title>Frequently Asked Questions</title>
      <link>https://sagemaker-workshop.com/security_for_sysops/faq.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_sysops/faq.html</guid>
      <description>The following is a compiled list of questions or issues you may face while going through these labs. If you encounter any issues, hopefully you will find helpful guidance below.
Q: I am trying to execute a cell in Jupyter Notebook but nothing happens.
A: Check whether the kernel has finished loading. You can see kernel status in the upper right corner of the Notebook. For the purpose of this workshop, the kernel should be conda_tensorflow_p27.</description>
    </item>
    
    <item>
      <title>Frequently Asked Questions</title>
      <link>https://sagemaker-workshop.com/security_for_users/faq.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sagemaker-workshop.com/security_for_users/faq.html</guid>
      <description>The following is a compiled list of questions or issues you may face while going through these labs. If you encounter any issues, hopefully you will find helpful guidance below.
Q: I am trying to execute a cell in Jupyter Notebook but nothing happens.
A: Check whether the kernel has finished loading. You can see kernel status in the upper right corner of the Notebook. For the purpose of this workshop, the kernel should be conda_tensorflow_p27.</description>
    </item>
    
  </channel>
</rss>
